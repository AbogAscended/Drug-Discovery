{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from CharRNN import CharRNNV2\n",
    "from Generation import *\n",
    "from DataLoader import *\n",
    "import torch\n",
    "from onehotencoder import OneHotEncoder\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "endecode = OneHotEncoder()\n",
    "vocab_size = OneHotEncoder.get_vocab_size(self = endecode)\n",
    "num_layers = 3\n",
    "n_gram = 1\n",
    "dropped_out = 0.2\n",
    "num_workers = 5\n",
    "hidden_size = 1024\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "temp = 1\n",
    "p = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "file_paths = [f'data/seqs_len{i}.txt' for i in range(18, 52)]\n",
    "Data = Data(filepaths=file_paths,encoder=endecode,n_gram=n_gram,batch_size=batch_size,num_workers=num_workers,num_epochs=num_epochs)\n",
    "train_loader, val_loader, total_steps, warmup_steps = Data.get_loaders()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "charRNN = CharRNNV2(vocab_size, num_layers, n_gram, total_steps, warmup_steps, learning_rate, hidden_size, dropped_out).to(device)\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    accelerator=\"cuda\",\n",
    "    precision='16-mixed',\n",
    "    gradient_clip_val=5.0,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"char_rnn\"),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\"),\n",
    "        EarlyStopping(monitor=\"valid_loss\", patience=5),\n",
    "    ],\n",
    "    profiler=\"pytorch\",\n",
    ")\n",
    "tuner = Tuner(trainer)\n",
    "lr_find_results = tuner.lr_find(\n",
    "    charRNN,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1.0,\n",
    "    early_stop_threshold=None,\n",
    "    update_attr=True,\n",
    ")\n",
    "trainer.fit(charRNN, train_loader, val_loader)\n",
    "torch.save(charRNN.state_dict(), \"Models/charRNNv1-gram.pt\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 335, in _exit_function\n",
      "    info('process shutting down')\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 52, in info\n",
      "    def info(msg, *args):\n",
      "    \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 323, in _exit_function\n",
      "    def _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n",
      "    \n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 323, in _exit_function\n",
      "    def _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n",
      "    \n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers(0)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers(0)\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 229, in _finalize_close\n",
      "    notempty.notify()\n",
      "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 410, in notify\n",
      "    waiter.release()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 227, in _finalize_close\n",
      "    with notempty:\n",
      "         ^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 300, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "charRNN = torch.load('Models/charRNNv1-gram.pt').to(device)\n",
    "filepath = 'data/GRUOnly1P1-gram.txt'\n",
    "generator = Generator(charRNN, endecode, vocab_size, n_gram, p, temp)\n",
    "generator.generate(filepath)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
