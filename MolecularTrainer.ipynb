{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from CharRNN import CharRNNV2\n",
    "from Generation import *\n",
    "from DataLoader import *\n",
    "import torch\n",
    "from onehotencoder import OneHotEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "endecode = OneHotEncoder()\n",
    "vocab_size = OneHotEncoder.get_vocab_size(self = endecode)\n",
    "num_layers = 3\n",
    "n_gram = 1\n",
    "dropped_out = 0.2\n",
    "num_workers = 5\n",
    "hidden_size = 1024\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "temp = 1\n",
    "p = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "file_paths = [f'data/seqs_len{i}.txt' for i in range(18, 52)]\n",
    "Data = Data(filepaths=file_paths,encoder=endecode,n_gram=n_gram,batch_size=batch_size,num_workers=num_workers,num_epochs=num_epochs)\n",
    "train_loader, val_loader, total_steps, warmup_steps = Data.get_loaders()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "charRNN = CharRNNV2(vocab_size, num_layers, n_gram, total_steps, warmup_steps, learning_rate, hidden_size, dropped_out).to(device)\n",
    "trainer = Trainer(\n",
    "    auto_lr_find=True,\n",
    "    max_epochs=200,\n",
    "    accelerator=\"cuda\",\n",
    "    precision='16-mixed',\n",
    "    gradient_clip_val=5.0,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"char_rnn\"),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\"),\n",
    "        EarlyStopping(monitor=\"valid_loss\", patience=5),\n",
    "    ],\n",
    "    profiler=\"pytorch\",\n",
    ")\n",
    "trainer.tune(charRNN, train_loader, val_loader)\n",
    "trainer.fit(charRNN, train_loader, val_loader)\n",
    "torch.save(charRNN.state_dict(), \"Models/charRNNv1-gram.pt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "charRNN = torch.load('Models/charRNNv1-gram.pt').to(device)\n",
    "filepath = 'data/GRUOnly1P1-gram.txt'\n",
    "generator = Generator(charRNN, endecode, vocab_size, n_gram, p, temp)\n",
    "generator.generate(filepath)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
