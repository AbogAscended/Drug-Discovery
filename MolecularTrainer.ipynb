{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:11:39.128693Z",
     "start_time": "2025-05-03T01:11:37.164525Z"
    }
   },
   "source": [
    "from CharRNN import CharRNNV2\n",
    "from Generation import *\n",
    "from DataLoader import *\n",
    "import torch\n",
    "from onehotencoder import OneHotEncoder\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:11:39.171172Z",
     "start_time": "2025-05-03T01:11:39.169487Z"
    }
   },
   "source": [
    "endecode = OneHotEncoder()\n",
    "vocab_size = OneHotEncoder.get_vocab_size(self = endecode)\n",
    "num_layers = 3\n",
    "n_gram = 1\n",
    "dropped_out = 0.2\n",
    "num_workers = 5\n",
    "hidden_size = 1024\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "temp = 1\n",
    "p = 1"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T01:11:39.973105Z",
     "start_time": "2025-05-03T01:11:39.213318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_paths = [f'data/seqs_len{i}.txt' for i in range(18, 52)]\n",
    "Data = Data(filepaths=file_paths,encoder=endecode,n_gram=n_gram,batch_size=batch_size,num_workers=num_workers,num_epochs=num_epochs)\n",
    "train_loader, val_loader, total_steps, warmup_steps = Data.get_loaders()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-03T01:11:39.978168Z"
    }
   },
   "source": [
    "charRNN = CharRNNV2(vocab_size, num_layers, n_gram, total_steps, warmup_steps, learning_rate, hidden_size, dropped_out).to(device)\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    accelerator=\"cuda\",\n",
    "    precision='16-mixed',\n",
    "    gradient_clip_val=5.0,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"char_rnn\"),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\"),\n",
    "        EarlyStopping(monitor=\"valid_loss\", patience=5),\n",
    "    ],\n",
    "    profiler=\"pytorch\",\n",
    ")\n",
    "tuner = Tuner(trainer)\n",
    "lr_find_results = tuner.lr_find(\n",
    "    charRNN,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1.0,\n",
    "    early_stop_threshold=None,\n",
    "    update_attr=True,\n",
    ")\n",
    "trainer.fit(charRNN, train_loader, val_loader)\n",
    "torch.save(charRNN.state_dict(), \"Models/charRNNv1-gram.pt\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:22,  4.36it/s][W502 18:11:44.530194344 collection.cpp:647] Warning: [pl][profile][LightningModule]CharRNNV2.optimizer_step (function operator())\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [00:01<00:00, 73.51it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:01<00:00, 59.58it/s]\n",
      "Learning rate set to 0.0002187761623949553\n",
      "Restoring states from the checkpoint path at /home/abog/PycharmProjects/Drug-Discovery/.lr_find_12ace012-77b9-4f8a-93c5-01934b4ebc84.ckpt\n",
      "Restored all states from the checkpoint at /home/abog/PycharmProjects/Drug-Discovery/.lr_find_12ace012-77b9-4f8a-93c5-01934b4ebc84.ckpt\n",
      "FIT Profiler Report\n",
      "Profile stats for: records\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us      53.397ms        80.15%      53.397ms      17.799ms             3  \n",
      "              [pl][module]torch.nn.modules.rnn.GRU: GRU         0.00%       0.000us         0.00%       0.000us       0.000us      45.075ms        67.66%      45.075ms       2.146ms            21  \n",
      "autograd::engine::evaluate_function: CudnnRnnBackwar...         0.06%      43.230us         8.04%       5.711ms       1.904ms       0.000us         0.00%      40.480ms      13.493ms             3  \n",
      "                                      CudnnRnnBackward0         0.03%      22.310us         7.98%       5.667ms       1.889ms       0.000us         0.00%      40.480ms      13.493ms             3  \n",
      "                              aten::_cudnn_rnn_backward         4.23%       3.003ms         7.95%       5.645ms       1.882ms      40.272ms        60.45%      40.480ms      13.493ms             3  \n",
      "                                       aten::_cudnn_rnn         3.09%       2.197ms        11.09%       7.873ms       1.312ms      18.118ms        27.20%      36.768ms       6.128ms             6  \n",
      "ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      21.017ms        31.55%      21.017ms      45.393us           463  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.training...         1.39%     983.738us         9.04%       6.420ms       2.140ms       0.000us         0.00%      19.052ms       6.351ms             3  \n",
      "              [pl][module]torch.nn.modules.rnn.GRU: GRU         0.18%     129.810us         6.47%       4.598ms       1.533ms       0.000us         0.00%      18.642ms       6.214ms             3  \n",
      "                                              aten::gru         0.07%      48.480us         6.29%       4.468ms       1.489ms       0.000us         0.00%      18.642ms       6.214ms             3  \n",
      "                        [pl][profile]run_training_batch         0.11%      80.160us        34.88%      24.771ms       8.257ms       0.000us         0.00%      13.268ms       4.423ms             3  \n",
      "[pl][profile][LightningModule]CharRNNV2.optimizer_st...        25.67%      18.234ms        34.75%      24.678ms       8.226ms       0.000us         0.00%      13.268ms       4.423ms             3  \n",
      "                                          ProfilerStep*         8.56%       6.076ms        55.43%      39.371ms      13.124ms       0.000us         0.00%      11.980ms       3.993ms             3  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.training...         0.00%       0.000us         0.00%       0.000us       0.000us      11.557ms        17.35%      11.557ms       3.852ms             3  \n",
      "ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      10.747ms        16.13%      10.747ms      32.468us           331  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_nt_n_tilesize192x12...         0.00%       0.000us         0.00%       0.000us       0.000us       9.439ms        14.17%       9.439ms     629.282us            15  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us       4.521ms         6.79%       4.521ms       1.507ms             3  \n",
      "                              Optimizer.step#AdamW.step         0.58%     413.470us         1.15%     819.009us     273.003us       0.000us         0.00%       4.506ms       1.502ms             3  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize96x128...         0.00%       0.000us         0.00%       0.000us       0.000us       3.761ms         5.64%       3.761ms      72.318us            52  \n",
      "void cutlass::Kernel2<cutlass_75_wmma_tensorop_f16_s...         0.00%       0.000us         0.00%       0.000us       0.000us       3.520ms         5.28%       3.520ms      59.666us            59  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 71.023ms\n",
      "Self CUDA time total: 66.619ms\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | Mode \n",
      "------------------------------------------\n",
      "0 | GRU    | GRU    | 15.8 M | train\n",
      "1 | linear | Linear | 55.3 K | train\n",
      "------------------------------------------\n",
      "15.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 M    Total params\n",
      "63.541    Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "charRNN = torch.load('Models/charRNNv1-gram.pt').to(device)\n",
    "filepath = 'data/GRUOnly1P1-gram.txt'\n",
    "generator = Generator(charRNN, endecode, vocab_size, n_gram, p, temp)\n",
    "generator.generate(filepath)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
